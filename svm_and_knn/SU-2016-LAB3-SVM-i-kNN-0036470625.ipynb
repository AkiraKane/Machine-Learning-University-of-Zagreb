{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "## Strojno učenje 2016./2017.\n",
    "\n",
    "<a href=\"http://www.fer.unizg.hr/predmet/su\">http://www.fer.unizg.hr/predmet/su</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratorijska vježba 3: Stroj potpornih vektora i algoritam k-najbližih susjeda\n",
    "\n",
    "(c) 2015-2016 Jan Šnajder, Domagoj Alagić\n",
    "\n",
    "<i>Verzija: 0.2</i> <br/>\n",
    "<i>Zadnji put ažurirano: 9. studenog 2016.</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objavljeno: **9. studenog 2016.**<br>\n",
    "Rok za predaju: U terminu vježbe u tjednu od **14. studenog 2016.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upute\n",
    "\n",
    "Treća laboratorijska vježba sastoji se od sedam zadataka. Kako bi kvalitetnije, ali i na manje zamoran način usvojili gradivo ovog kolegija, potrudili smo se uključiti tri vrste zadataka: **1)** implementacija manjih algoritama, modela ili postupaka; **2)** eksperimenti s raznim modelima te njihovim hiperparametrima, te **3)** primjena modela na (stvarnim) podatcima. Ovim zadatcima pokrivamo dvije paradigme učenja: učenje izgradnjom (engl. *learning by building*) i učenje eksperimentiranjem (engl. *learning by experimenting*).\n",
    "\n",
    "U nastavku slijedite upute navedene u ćelijama s tekstom. Rješavanje vježbe svodi se na **dopunjavanje ove bilježnice**: umetanja ćelije ili više njih **ispod** teksta zadatka, pisanja odgovarajućeg kôda te evaluiranja ćelija. \n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kôd koji ste napisali. Kod predaje vježbe, morate biti u stanju na zahtjev asistenta (ili demonstratora) preinačiti i ponovno evaluirati Vaš kôd. Nadalje, morate razumjeti teorijske osnove onoga što radite, u okvirima onoga što smo obradili na predavanju. Ispod nekih zadataka možete naći i pitanja koja služe kao smjernice za bolje razumijevanje gradiva (**nemojte pisati** odgovore na pitanja u bilježnicu). Stoga se nemojte ograničiti samo na to da riješite zadatak, nego slobodno eksperimentirajte. To upravo i jest svrha ovih vježbi.\n",
    "\n",
    "Vježbe trebate raditi **samostalno**. Možete se konzultirati s drugima o načelnom načinu rješavanja, ali u konačnici morate sami odraditi vježbu. U protivnome vježba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import mlutils\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Klasifikator SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoznajte se s klasom [`svm.SVC`](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC), koja ustvari implementira sučelje prema implementaciji [`libsvm`](http://www.csie.ntu.edu.tw/~cjlin/libsvm/). Primijenite model `SVC` s linearnom jezgrenom funkcijom (tj. bez preslikavanja primjera u prostor značajki) na skup podataka `seven` (dan niže) s $N=7$ primjera. Ispišite koeficijente $w_0$ i $\\mathbf{w}$. Ispišite dualne koeficijente i potporne vektore. Završno, koristeći funkciju `mlutils.plot_2d_svc_problem` iscrtajte podatke, decizijsku granicu i marginu. Funkcija prima podatke, oznake i klasifikator (objekt klase `SVC`). Izračunajte širinu margine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [ 3.99951172] [[ -9.99707031e-01  -2.92968750e-04]]\n",
      "Dual koef [[ -4.99707031e-01  -1.46484375e-04   4.99853516e-01]]\n",
      "\n",
      "SV: [[ 5.  2.]\n",
      " [ 5.  4.]\n",
      " [ 3.  2.]]\n",
      "\n",
      "Width: 1.99921875\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD7CAYAAAC2a1UBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f558faf22d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "seven_X = np.array([[2,1], [2,3], [1,2], [3,2], [5,2], [5,4], [6,3]])\n",
    "seven_y = np.array([1, 1, 1, 1, -1, -1, -1])\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(seven_X, seven_y)\n",
    "\n",
    "print 'W:', model.intercept_, model.coef_\n",
    "print 'Dual koef', model.dual_coef_\n",
    "print '\\nSV:', model.support_vectors_\n",
    "\n",
    "print '\\nWidth:', 2 * min(abs(model.decision_function(seven_X)))\n",
    "\n",
    "\n",
    "mlutils.plot_2d_svc_problem(seven_X, seven_y, svc=model)\n",
    "#mlutils.plot_2d_clf_problem(seven_X, seven_y, h=model.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koliko iznosi širina margine? <br>\n",
    "**Q:** Koji primjeri su potporni vektori i zašto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definirajte funkciju `hinge(model, x, y)` koja izračunava gubitak zglobnice modela SVM (s linearnom jezgrom) na primjeru `x`. Izračunajte gubitke modela naučenog na skupu `seven` za primjere $\\mathbf{x}^{(2)}=(3,2)$ i $\\mathbf{x}^{(1)}=(3.5,2)$ koji su označeni pozitivno ($y=1$) te za $\\mathbf{x}^{(3)}=(4,2)$ koji je označen negativno ($y=-1$). Također, izračunajte prosječni gubitak SVM-a na skupu `seven`. Uvjerite se da je rezultat identičan onome koji biste dobili primjenom ugrađene funkcije [`metrics.hinge_loss`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.hinge_loss.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKlearn hinge: 0.0\n",
      "Hinge: [ 0.00019531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <type 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-14ce9cd2aaf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Hinge:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinge_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Hinge:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinge_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Hinge:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhinge_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mhinge_loss\u001b[1;34m(y_true, pred_decision, labels, sample_weight)\u001b[0m\n\u001b[0;32m   1657\u001b[0m     \u001b[1;36m0.56\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \"\"\"\n\u001b[1;32m-> 1659\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_decision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m     \u001b[0mpred_decision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_decision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \"\"\"\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n",
      "\u001b[1;32m/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             raise TypeError(\"Expected sequence or array-like, got %s\" %\n\u001b[1;32m--> 118\u001b[1;33m                             type(x))\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected sequence or array-like, got <type 'int'>"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "print 'SKlearn hinge:', hinge_loss(seven_y, model.predict(seven_X))\n",
    "\n",
    "def hinge(model, x,  y):\n",
    "    return max(0, 1 - y * model.decision_function(x))\n",
    "\n",
    "x1 = np.array([3, 2])\n",
    "x2 = [3.5, 2]\n",
    "x3 = [4, 2]\n",
    "    \n",
    "print 'Hinge:', hinge(model, x1, [1]), hinge_loss(1, model.predict(x1.reshape(1, -1)))\n",
    "print 'Hinge:', hinge(model, x2, [1]), hinge_loss([1], model.predict(x2))\n",
    "print 'Hinge:', hinge(model, x3, [-1]), hinge_loss([-1], model.predict(x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vratit ćemo se na skupove podataka `outlier` ($N=8$) i `unsep` ($N=8$) iz prošle laboratorijske vježbe (dani niže) i pogledati kako se model SVM-a nosi s njima. Naučite ugrađeni model SVM-a (s linearnom jezgrom) na ovim podatcima i iscrtajte decizijsku granicu (skupa s marginom). Također ispišite točnost modela korištenjem funkcije [`metrics.accuracy_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "outlier_X = np.append(seven_X, [[12,8]], axis=0)\n",
    "outlier_y = np.append(seven_y, -1)\n",
    "\n",
    "unsep_X = np.append(seven_X, [[2,2]], axis=0)\n",
    "unsep_y = np.append(seven_y, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Zašto stršeća vrijednost ne utječe na SVM? <br>\n",
    "**Q:** Kako se linearan SVM nosi s linearno neodvojivim skupom podataka? <br>\n",
    "**Q:** Zašto SVM ipak uspjeva pronaći nekakvu granicu kod linearno neodvojivog problema, iako koristimo linearnu jezgru?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Nelinearan SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovaj zadatak pokazat će kako odabir jezgre utječe na kapacitet SVM-a. Na skupu `unsep` iz prošlog zadatka trenirajte tri modela SVM s različitim jezgrenim funkcijama: linearnom, polinomijalnom i radijalnom baznom (RBF) funkcijom. Varirajte parametar $C$ po vrijednostima $C\\in\\{10^{-2},1,10^2\\}$, dok za ostale parametre (stupanj polinoma za polinomijalnu jezgru odnosno parametar $\\gamma$ za jezgru RBF) koristite podrazumijevane vijednosti. Prikažite granice između klasa (i margine) na grafikonu organiziranome u polje $3x3$, gdje su stupci različite jezgre, a retci različite vrijednosti parametra $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Optimizacija hiperparametara SVM-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pored hiperparametra $C$, model SVM s jezgrenom funkcijom RBF ima i dodatni hiperparametar $\\gamma=\\frac{1}{2\\sigma^2}$ (preciznost). Taj parametar također određuje složenost modela: velika vrijednost za $\\gamma$ znači da će RBF biti uska, primjeri će biti preslikani u prostor u kojem su (prema skalarnome produktu) međusobno vrlo različiti, što će rezultirati složenijim modelima. Obrnuto, mala vrijednost za $\\gamma$ znači da će RBF biti široka, primjeri će biti međusobno sličniji, što će rezultirati jednostavnijim modelima. To ujedno znači da, ako odabremo veći $\\gamma$, trebamo jače regularizirati model, tj. trebamo odabrati manji $C$, kako bismo spriječili prenaučenost. Zbog toga je potrebno zajednički optimirati hiperparametre $C$ i $\\gamma$, što se tipično radi iscrpnim pretraživanjem po rešetci (engl. *grid search*). Ovakav pristup primjenjuje se kod svih modela koji sadrže više od jednog hiperparametra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definirajte funkciju \n",
    "\n",
    "> `grid_search(X_train, X_validate, y_train, y_validate, (c1,c2), (g1,g2), error_surface=False)` \n",
    "\n",
    "koja optimizira parametre $C$ i $\\gamma$ pretraživanjem po rešetci. Funkcija treba pretražiti parametre $C\\in\\{2^{c_1},2^{c_1+1},\\dots,2^{c_2}\\}$ i $\\gamma\\in\\{2^{g_1},2^{g_1+1},\\dots,2^{g_2}\\}$. Funkcija treba vratiti optimalne parametre $(C^*,\\gamma^*)$, tj. one za koje na skupu za provjeru model ostvaruju najmanju pogrešku. Dodatno, ako je `surface=True`, funkcija treba vratiti matrice (tipa `ndarray`) pogreške modela (očekivanje gubitka 0-1) na skupu za učenje i skupu za provjeru. Svaka je matrica dimenzija $(c_2-c_1+1)\\times(g_2-g_1+1)$ (retci odgovaraju različitim vrijednostima za $C$, a stupci različitim vrijednostima za $\\gamma$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, zero_one_loss\n",
    "\n",
    "def grid_search(X_train, X_validate, y_train, y_validate, (c1,c2), (g1,g2), error_surface=False) :\n",
    "    # Vaš kôd ovdje...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomoću funkcije [`datasets.make_classification`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) generirajte **dva** skupa podataka od $N=200$ primjera: jedan s $n=2$ dimenzije i drugi s $n=1000$ dimenzija. Primjeri neka dolaze iz dviju klasa, s time da svakoj klasi odgovaraju dvije grupe (`n_clusters_per_class=2`), kako bi problem bio nešto složeniji, tj. nelinearniji. Neka sve značajke budu informativne. Podijelite skup primjera na skup za učenje i skup za ispitivanje u omjeru 1:1.\n",
    "\n",
    "Na oba skupa optimirajte SVM s jezgrenom funkcijom RBF, u rešetci $C\\in\\{2^{-5},2^{-4},\\dots,2^{15}\\}$ i $\\gamma\\in\\{2^{-15},2^{-14},\\dots,2^{3}\\}$. Prikažite površinu pogreške modela na skupu za učenje i skupu za provjeru, i to na oba skupa podataka (ukupno četiri grafikona) te ispišite optimalne kombinacije hiperparametara. Prikažite i granicu između klasa za dvodimenzijski skup. Za prikaz površine pogreške modela možete koristiti funkciju `plot_error_surface` iz paketa `mlutils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Razlikuje li se površina pogreške na skupu za učenje i skupu za ispitivanje? Zašto? <br>\n",
    "**Q:** U prikazu površine pogreške, koji dio površine odgovara prenaučenosti, a koji podnaučenosti? Zašto? <br>\n",
    "**Q:** Kako broj dimenzija $n$ utječe na površinu pogreške, odnosno na optimalne hiperparametre $(C^*, \\gamma^*)$? <br>\n",
    "**Q:** Preporuka je da povećanje vrijednosti za $\\gamma$ treba biti popraćeno smanjenjem vrijednosti za $C$. Govore li vaši rezultati u prilog toj preporuci? Obrazložite. <br>\n",
    "**Q:** Podrazumijevana vrijednost parametara je $C=1$ i $\\gamma=1/n$. Bi li te vrijednosti bile optimalne u ovom slučaju?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Utjecaj standardizacije značajki kod SVM-a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za mnoge je modele bitno prije treniranja skalirati značajke, kako bi se spriječilo da značajke s većim numeričkim rasponima dominiraju nad onima s manjim numeričkim rasponima. To vrijedi i za SVM, kod kojega skaliranje nerijetko može znatno poboljšati rezultate. Svrha ovog zadataka jest eksperimentalno utvrditi utjecaj skaliranja značajki na točnost SVM-a.\n",
    "\n",
    "Generirat ćemo dvoklasni skup od $N=500$ primjera s $n=2$ značajke, tako da je dimenzija $x_1$ većeg iznosa i većeg raspona od dimenzije $x_0$, te ćemo dodati jedan primjer koji vrijednošću značajke $x_1$ odskače od ostalih primjera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=500,n_features=2,n_classes=2,n_redundant=0,n_clusters_per_class=1)\n",
    "X[:,1] = X[:,1]*100+1000\n",
    "X[0,1] = 3000\n",
    "\n",
    "mlutils.plot_2d_svc_problem(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite funkciju za iscrtavanje histograma [`hist`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist). Prikažite histograme vrijednosti značajki $x_0$ i $x_1$ (ovdje i u sljedećim zadatcima koristite `bins=50`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite razred [`preprocessing.MinMaxScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html). Prikažite histograme vrijednosti značajki $x_0$ i $x_1$ ako su iste skalirane min-max skaliranjem (ukupno dva histograma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako radi ovo skaliranje? <br>\n",
    "**Q:** Dobiveni histogrami su vrlo slični. U čemu je razlika? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proučite razred [`preprocessing.StandardScaler`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Prikažite histograme vrijednosti značajki $x_0$ i $x_1$ ako su iste skalirane standardnim skaliranjem (ukupno dva histograma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako radi ovo skaliranje? <br>\n",
    "**Q:** Dobiveni histogrami su vrlo slični. U čemu je razlika? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podijelite skup primjera na skup za učenje i skup za ispitivanje u omjeru 1:1. Trenirajte SVM s jezgrenom funkcijom RBF na skupu za učenje i ispitajte točnost modela na skupu za ispitivanje, koristeći tri varijante gornjeg skupa: neskalirane značajke, standardizirane značajke i min-max skaliranje. Koristite podrazumijevane vrijednosti za $C$ i $\\gamma$. Izmjerite točnost svakog od triju modela na skupu za učenje i skupu za ispitivanje. Ponovite postupak više puta (npr. 30) te uprosječite rezultate (u svakom ponavljanju generirajte podatke kao što je dano na početku ovog zadatka).\n",
    "\n",
    "**NB:** Na skupu za učenje treba najprije izračunati parametre skaliranja te zatim primijeniti skaliranje (funkcija `fit_transform`), dok na skupu za ispitivanje treba samo primijeniti skaliranje s parametrima koji su dobiveni na skupu za učenje (funkcija `transform`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Jesu li rezultati očekivani? Obrazložite. <br>\n",
    "**Q:** Bi li bilo dobro kada bismo funkciju `fit_transform` primijenili na cijelom skupu podataka? Zašto? Bi li bilo dobro kada bismo tu funkciju primijenili zasebno na skupu za učenje i zasebno na skupu za ispitivanje? Zašto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. k-najbližih susjeda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovom zadatku promatrat ćemo jednostavan klasifikacijski model imena **algoritam k-najbližih susjeda**. Najprije ćete ga samostalno isprogramirati kako biste se detaljno upoznali s radom ovog modela, a zatim ćete prijeći na analizu njegovih hiperparametara (koristeći ugrađeni razred, zbog efikasnosti)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementirajte klasu `KNN` koja implementira algoritam $k$ najbližih susjeda. Neobavezan parametar konstruktora jest broj susjeda `n_neighbours` ($k$), čija je podrazumijevana vrijednost 3. Definirajte metode `fit(X, y)` i `predict(X)`, koje služe za učenje modela odnosno predikciju. Kao mjeru udaljenosti koristite euklidsku udaljenost ([`scipy.linalg.norm`](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.norm.html); pripazite na parametar `axis`). Nije potrebno implementirati nikakvu težinsku funkciju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import norm\n",
    "from bisect import insort\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, n_neighbors=3):\n",
    "        # Vaš kôd ovdje...\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        # Vaš kôd ovdje...\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        # Vaš kôd ovdje...\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako biste se uvjerili da je Vaša implementacija ispravna, usporedite ju s ugrađenom implementacijom u razredu [`neighbors.KNeighborsClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Budući da spomenuti razred koristi razne optimizacijske trikove pri pronalasku najboljih susjeda, obavezno postavite parametar `algorithm=brute`, jer bi se u protivnom moglo dogoditi da Vam se predikcije razlikuju. Usporedite modele na sljedećem (umjetnom) skupu podataka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X_art, y_art = make_classification(n_samples=100, n_features=2, n_classes=2, n_redundant=0, n_clusters_per_class=2)\n",
    "mlutils.plot_2d_clf_problem(X_art, y_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomoću funkcije `mlutils.plot_2d_clf_problem` iscrtajte prostor primjera i područja koja odgovaraju prvoj odnosno drugoj klasi. Eksperimentirajte s različitim vrijednostima za broj primjera $N$, broj susjeda $k$ i broj klasa $K$.\n",
    "\n",
    "**NB:** Implementacija algoritma `KNeighborsClassifier` iz sklearna vjerojatno će raditi brže od Vaše implementacije, pa koristite nju za iscrtavanje grafa. Naime, za iscrtavanje grafa potrebno je napraviti predikciju za svaku točku u regiji iscrtavanja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako $k$ utječe na izgled granice između klasa? A broj primjera $N$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Analiza algoritma k-najbližih susjeda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritam k-nn ima hiperparametar $k$ (broj susjeda). Taj hiperparametar izravno utječe na složenost algoritma, pa je stoga izrazito važno dobro odabrati njegovu vrijednost. Kao i kod mnogih drugih algoritama, tako i kod algoritma k-nn optimalna vrijednost hiperametra $k$ ovisi o konkretnom problemu, uključivo broju primjera $N$, broju značajki (dimenzija) $n$ te broju klasa $K$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako bismo dobili pouzdanije rezultate, potrebno je mjerenja ponoviti na različitim skupovima podataka i zatim uprosječiti dobivene vrijednosti pogrešaka. Definirajte funkciju\n",
    "\n",
    "> `knn_eval(n_instances=100, n_features=2, n_classes=2, n_informative=2, test_size=0.3, k_range=(1, 20), n_trials=100)`\n",
    "\n",
    "koja trenira i ispituje model k-nn na ukupno `n_instances` primjera, i to tako da za svaku vrijednost hiperparametra iz zadanog intervala `k_range` ponovi `n_trials` mjerenja, generirajući za svako od njih nov skup podataka pomoću funkcije [`datasets.make_classification`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) i dijeleći ga na skup za učenje i skup za ispitivanje koristeći funkciju [`sklearn.cross_validation.train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html). Udio skupa za ispitivanje definiran je parametrom `test_size`. Vrijednosti parametara `n_instances`, `n_features`, `n_classes` i `n_informative` proslijedite funkciji `make_classification` te dodatno postavite `n_redundant=0` i `n_clusters_per_class=1`. Povratne vrijednosti funkcije jest trojka `(best_k, train_errors, test_errors)`. Vrijednost `best_k` je optimalna vrijednost hiperparametra $k$ (vrijednost za koju je pogreška na skupu za ispitivanje najmanja). Vrijednosti `train_errors` i `test_errors`  liste su pogrešaka na skupu za učenja odnosno skupu za testiranje za sve razmatrane vrijednosti hiperparametra $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def knn_eval(n_instances=100, n_features=2, n_classes=2, n_informative=2, test_size=0.3, k_range=(1, 20), n_trials=100):\n",
    "    \n",
    "    # Vaš kôd ovdje...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomoću funkcije `knn_eval` iz (a) dijela zadatka, iscrtajte pogrešku učenja i ispitivanja kao funkcije hiperparametra $k$, $k\\in\\{1,\\dots,20\\}$, za $N=200$ primjera. Ispišite i optimalnu vrijednost za $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kojem području odgovara prenaučenost, a kojem podnaučenost modela? Zašto? <br>\n",
    "**Q:** Je li uvijek moguće doseći pogrešku od 0 na skupu za učenje?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomoću funkcije `knn_eval` iz (a) dijela zadatka, iscrtajte pogreške učenja i ispitivanja kao funkcije hiperparametra $k$, $k\\in\\{1,\\dots,20\\}$, za $N=\\{100, 500, 1000, 3000\\}$ primjera. Načinite 4 zasebna grafikona (generirajte ih u 2x2 polju). U svakoj iteraciji ispišite optimalnu vrijednost hiperparametra $k$ (najlakše kao naslov grafikona)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Nerobusnost algoritma k-nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svrha ovog zadatka jest analizirati u kojoj je mjeri algoritam k-nn osjetljiv na razlike u mjernoj skali između pojedinih dimenzija te na prisutnost nebitnih značajki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krenite od umjetnog skupa podataka danog u nastavku. Zatim napravite kopiju tog skupa podataka (pogledajte [`copy.deepcopy`](https://docs.python.org/2/library/copy.html#copy.deepcopy)) i preinačite ju tako da jednu dimenziju pomnožite sa 100. Oba skupa podijelite na skup za učenje i skup za ispitivanje u omjeru 7:3, pri čemu obratite pozornost na to da oba skupa podijelite na identičan način. Trenirajte modele k-nn na skaliranoj i neskaliranoj inačici skupa za učenje (s pretpostavljenim parametrima), a zatim ispitajte model na odgovarajućim ispitnim inačicama skupova."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_classes=2, n_redundant=0, n_clusters_per_class=2)\n",
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Zašto je ovaj problem tako izražen kod algoritma k-nn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako bismo provjerili u kojoj je mjeri algoritam k-nn osjetljiv na prisustvo nebitnih značajki, možemo iskoristiti funkciju `make_classification` kako bismo generirali skup primjera kojemu su neke od značajki nebitne. Naime, parametar `n_informative` određuje broj bitnih značajki, dok parametar `n_features` određuje ukupan broj značajki. Ako je `n_features > n_informative`, onda će neke od značajki biti nebitne. Umjesto da izravno upotrijebimo funkciju `make_classification`, upotrijebit ćemo funkciju `knn_eval` iz zadatka (7a), jer ćemo na taj način dobiti pouzdanije procjene.\n",
    "\n",
    "Koristite funkciju `knn_eval` na dva načina. U oba koristite $N=1000$ primjera, $n=10$ značajki i $K=5$ klasa, ali za prvi neka su svih 10 značajki bitne, a za drugi neka je bitno samo 5 od 10 značajki. Ispišite pogreške učenja i ispitivanja za oba modela za optimalnu vrijednost $k$ (vrijednost za koju je ispitna pogreška najmanja)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Zašto nebitne značajke ovoliko utječu na perfomanse modela?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
