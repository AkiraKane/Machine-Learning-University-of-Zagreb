{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveučilište u Zagrebu<br>\n",
    "Fakultet elektrotehnike i računarstva\n",
    "\n",
    "## Strojno učenje 2016./2017.\n",
    "\n",
    "<a href=\"http://www.fer.unizg.hr/predmet/su\">http://www.fer.unizg.hr/predmet/su</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratorijska vježba 6: Vrednovanje klasifikatora i grupiranje\n",
    "\n",
    "(c) 2015-2017 Domagoj Alagić, Mladen Karan, Jan Šnajder\n",
    "\n",
    "<i>Verzija: 0.1</i> <br/>\n",
    "<i>Zadnji put ažurirano: 12. siječnja 2017.</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objavljeno: **12. siječnja 2017.**<br>\n",
    "Rok za predaju: U terminu vježbe u tjednu od **16. siječnja 2017.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upute\n",
    "\n",
    "Šesta laboratorijska vježba sastoji se od **pet** zadataka. Kako bi kvalitetnije, ali i na manje zamoran način usvojili gradivo ovog kolegija, potrudili smo se uključiti tri vrste zadataka: **1)** implementacija manjih algoritama, modela ili postupaka; **2)** eksperimenti s raznim modelima te njihovim hiperparametrima, te **3)** primjena modela na (stvarnim) podatcima. Ovim zadatcima pokrivamo dvije paradigme učenja: učenje izgradnjom (engl. *learning by building*) i učenje eksperimentiranjem (engl. *learning by experimenting*).\n",
    "\n",
    "U nastavku slijedite upute navedene u ćelijama s tekstom. Rješavanje vježbe svodi se na **dopunjavanje ove bilježnice**: umetanja ćelije ili više njih **ispod** teksta zadatka, pisanja odgovarajućeg kôda te evaluiranja ćelija. \n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kôd koji ste napisali. Kod predaje vježbe, morate biti u stanju na zahtjev asistenta (ili demonstratora) preinačiti i ponovno evaluirati Vaš kôd. Nadalje, morate razumjeti teorijske osnove onoga što radite, u okvirima onoga što smo obradili na predavanju. Ispod nekih zadataka možete naći i pitanja koja služe kao smjernice za bolje razumijevanje gradiva (**nemojte pisati** odgovore na pitanja u bilježnicu). Stoga se nemojte ograničiti samo na to da riješite zadatak, nego slobodno eksperimentirajte. To upravo i jest svrha ovih vježbi.\n",
    "\n",
    "Vježbe trebate raditi **samostalno**. Možete se konzultirati s drugima o načelnom načinu rješavanja, ali u konačnici morate sami odraditi vježbu. U protivnome vježba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Učitaj osnovne biblioteke...\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Matrice zabune i evaluacijske mjere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cilj ovog zadatka jest upoznati se s osnovnim evaluacijskim mjerama temeljenima na matrici zabune (engl. *confusion matrix*).\n",
    "\n",
    "Preuzmite Glass Identification Data Set, koji opisuje rezultate kemijske analize 214 stakala. Riječ je o klasifikacijskom problemu sa šest klasa: na temelju 9 kemijskih značajki stakla potrebno je, u svrhu forenzičke analize, odrediti o kojoj se od šest vrsta stakla radi. Skup podataka možete učitati na sljedeći način:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"./glass.csv\", delimiter=',')\n",
    "glass_X, glass_y = data[:,1:10], data[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1.         1.52101   13.64    ...,    0.         0.         1.     ]\n",
      " [   2.         1.51761   13.89    ...,    0.         0.         1.     ]\n",
      " [   3.         1.51618   13.53    ...,    0.         0.         1.     ]\n",
      " ..., \n",
      " [ 212.         1.52065   14.36    ...,    1.64       0.         7.     ]\n",
      " [ 213.         1.51651   14.38    ...,    1.57       0.         7.     ]\n",
      " [ 214.         1.51711   14.23    ...,    1.67       0.         7.     ]]\n"
     ]
    }
   ],
   "source": [
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podijelite skup primjera na skup za učenje i na skup za ispitivanju u omjeru 1:1 (koristite funkciju [`model_selection train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)). Naučite SVM s linearnom jezgrom (s pretpostavljenim hiperparametrima) na skupu za učenje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(glass_X, glass_y, test_size=0.5)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "\n",
    "Upoznajte se s funkcijom [`metrics.confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) koja iz stvarnih oznaka i predikcija računa matricu zabune. Izračunajte matricu zabune za naučeni model SVM-a predstavljenog gore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22 17  0  0  0  0]\n",
      " [ 5 31  0  1  0  0]\n",
      " [ 2  4  0  0  0  0]\n",
      " [ 0  5  0  3  0  0]\n",
      " [ 1  4  0  0  0  0]\n",
      " [ 0  4  0  0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(test_y, model.predict(test_X))\n",
    "print cm\n",
    "\n",
    "# Cij, observation known to be in CLASS i but predicted to be in CLASS j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koja klasa ima najviše pogrešnih pozitivnih klasifikacija (engl. *false positives*), a koja najviše pogrešnih negativnih klasifikacija (engl. *false negatives*)? <br>\n",
    "**Q:** Što predstavljaju vrijednosti na dijagonali ove matrice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "Definirajte funkciju `twoway_confusion_matrix(cm, i)` koja prima matricu zabune `cm` dimenzija $K\\times K$ (pri čemu je $K$ broj klasa) i indeks klase $i$ te izračunava binarnu matricu zabune za klasu $i$ kao pozitivnu klasu. Izračunajte i ispišite binarne matrice zabune za svih 6 klasa iz skupa `glass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class index: 0\n",
      "[[22  8]\n",
      " [17 42]]\n",
      "\n",
      "Class index: 1\n",
      "[[31 34]\n",
      " [ 6 33]]\n",
      "\n",
      "Class index: 2\n",
      "[[ 0  0]\n",
      " [ 6 64]]\n",
      "\n",
      "Class index: 3\n",
      "[[ 3  1]\n",
      " [ 5 61]]\n",
      "\n",
      "Class index: 4\n",
      "[[ 0  0]\n",
      " [ 5 64]]\n",
      "\n",
      "Class index: 5\n",
      "[[ 8  0]\n",
      " [ 4 56]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def twoway_confusion_matrix(cm, i):\n",
    "    tp = cm[i, i]\n",
    "    tn = sum([cm[j, k] for j, k in zip(range(cm.shape[0]), range(cm.shape[1])) if j != i and k != i ])\n",
    "    \n",
    "    fp = sum([cm[i, j] for j in range(cm.shape[0]) if i != j])\n",
    "    fn = sum([cm[j, i] for j in range(cm.shape[0]) if i != j])\n",
    "    \n",
    "    return np.array([[tp, fn],[fp, tn]])\n",
    "\n",
    "for class_index in range(cm.shape[0]):\n",
    "    print '\\nClass index: %d' % class_index\n",
    "    print twoway_confusion_matrix(cm, class_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "\n",
    "Pomoću funkcija iz (a) i (b) dijela zadatka, definirajte funkcije `accuracy`, `precision`, `recall` i `f1` za izračun točnosti, preciznosti, odziva odnosno F1-mjere. Svaka od ovih funkcija uzima kao argumente stvarne oznake primjera `y_true` i predviđene oznake `y_pred`. Funkcije trebaju izračunavati mikro i makro varijante ovih mjera, što se određuje opcijom `averaging=micro` odnosno `averaging=macro` (podrazumijevana vrijednost).\n",
    "\n",
    "Izračunajte vrijednosti ovih evaluacijskih mjera na skupu `glass`. Uvjerite da vaša implementacija daje identične rezultate kao funkcije iz paketa [`metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). Ove funkcije pretpostavljaju makro-mjere, osim one za F1 koja može primiti i parametar koji definira hoće li se izračunati mikro ili makro vrijednost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_acc: 0.598130841121\n",
      "DIY_acc: 0.817021276596\n",
      "\n",
      "micro\n",
      "DIY_precision: 0.598130841121\n",
      "SKLEARN_precision: 0.598130841121\n",
      "\n",
      "micro\n",
      "DIY_recall: 0.598130841121\n",
      "SKLEARN_recall: 0.598130841121\n",
      "\n",
      "micro\n",
      "DIY_f1: 0.598130841121\n",
      "SKLEARN_f1: 0.598130841121\n",
      "\n",
      "macro\n",
      "DIY_precision: 0.493376068376\n",
      "SKLEARN_precision: 0.493376068376\n",
      "\n",
      "macro\n",
      "DIY_recall: 0.407267844768\n",
      "SKLEARN_recall: 0.407267844768\n",
      "\n",
      "macro\n",
      "DIY_f1: 0.424254049446\n",
      "SKLEARN_f1: 0.424254049446\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/weenkus/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "class Metrics(object):\n",
    "    @staticmethod\n",
    "    def get_precision(tp, tn, fn, fp):\n",
    "        return tp / float(tp + fp + 1e-16)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_recall(tp, tn, fn, fp):\n",
    "        return tp / float(tp + fn + 1e-16)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_f1(tp, tn, fn, fp):\n",
    "        recall = Metrics.get_recall(tp, tn, fn, fp)\n",
    "        precision = Metrics.get_precision(tp, tn, fn, fp)\n",
    "        return (2 * recall * precision) / float(precision + recall + 1e-16)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_params(cm_bin):\n",
    "        tp = cm_bin[0, 0]\n",
    "        tn = cm_bin[1, 1]\n",
    "        fn = cm_bin[1, 0]\n",
    "        fp = cm_bin[0, 1]\n",
    "        return tp, tn, fn, fp\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_micro_params(y_true, y_pred):\n",
    "        tp, tn, fn, fp = 0, 0, 0, 0\n",
    "        for tp_bin, tn_bin, fn_bin, fp_bin in Metrics.param_generator(y_true, y_pred):\n",
    "            tp += tp_bin\n",
    "            tn += tn_bin\n",
    "            fn += fn_bin\n",
    "            fp += fp_bin\n",
    "            \n",
    "        return tp, tn, fn, fp\n",
    "    \n",
    "    @staticmethod\n",
    "    def param_generator(y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        tp, tn, fn, fp = 0, 0, 0, 0\n",
    "        for class_index in range(len(set(y_true))):\n",
    "            cm_bin = twoway_confusion_matrix(cm, class_index)\n",
    "            tp_bin, tn_bin, fn_bin, fp_bin = Metrics.get_params(cm_bin) \n",
    "            \n",
    "            yield tp_bin, tn_bin, fn_bin, fp_bin\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_score(y_true, y_pred, calc_func, average='micro'):\n",
    "        if average == 'micro':\n",
    "            tp, tn, fn, fp = Metrics.get_micro_params(y_true, y_pred)    \n",
    "            return calc_func(tp, tn, fn, fp)\n",
    "        else:\n",
    "            scores = []\n",
    "            for tp_bin, tn_bin, fn_bin, fp_bin in Metrics.param_generator(y_true, y_pred):\n",
    "                score = calc_func(tp_bin, tn_bin, fn_bin, fp_bin)\n",
    "                scores.append(score)\n",
    "            \n",
    "            return sum(scores) / float(len(scores))\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        tp, tn, fn, fp = Metrics.get_micro_params(y_true, y_pred)\n",
    "        return (tp + tn) / float(tp + tn + fp + fn)\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision(y_true, y_pred, average='micro'):\n",
    "        return Metrics.get_score(y_true, y_pred, Metrics.get_precision, average)\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall(y_true, y_pred, average='micro'):\n",
    "        return Metrics.get_score(y_true, y_pred, Metrics.get_recall, average)\n",
    "    \n",
    "    @staticmethod\n",
    "    def f1_score(y_true, y_pred, average='micro'):\n",
    "        return Metrics.get_score(y_true, y_pred, Metrics.get_f1, average)\n",
    "            \n",
    "    \n",
    "\n",
    "y_pred = model.predict(test_X)\n",
    "y_true = test_y\n",
    "    \n",
    "print 'SK_acc:', accuracy_score(y_true, y_pred)\n",
    "print 'DIY_acc:', Metrics.accuracy(y_true, y_pred)\n",
    "print\n",
    "\n",
    "for score_type in ['micro', 'macro']:\n",
    "    for sklearn_function, my_function, score in zip(\n",
    "        [precision_score, recall_score, f1_score],\n",
    "        [Metrics.precision, Metrics.recall, Metrics.f1_score],\n",
    "        ['precision', 'recall', 'f1']\n",
    "    ):\n",
    "        print score_type\n",
    "        print 'DIY_{0}:'.format(score), my_function(y_true, y_pred, average=score_type)\n",
    "        print 'SKLEARN_{0}:'.format(score), sklearn_function(y_true, y_pred, average=score_type)\n",
    "        print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koja je razlika između mikro- i makro-procjene?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vrednovanje klasifikatora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako bismo se uvjerili koliko naš naučeni model zapravo dobro radi, nužno je provesti evaluaciju modela. Ovaj korak od presudne je važnosti u svim primjenama strojnog učenja, pa je stoga bitno znati provesti evaluaciju na ispravan način. U ovom zadatku fokusirat ćemo se na k-struku ugniježđenu unakrsnu provjeru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "\n",
    "Implementirajte funkciju `nested_kfold_cv(clf, param_grid, X, y, k1, k2)` koja provodi k-struku ugniježđenu unakrsnu provjeru. Argument `clf` predstavlja vaš klasifikator (nenaučena instanca), `param_grid` rječnik hiperparametara i njihovih vrijednosti koje se isprobavaju u učenju, `X` i `y` označeni skup podataka, a `k1` i `k2` broj preklopa u vanjskoj, odnosno unutarnjoj petlji. Međutim, unutarnju petlju možete izvesti korištenjem razreda [`model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Upoznajte se sa spomenutim razredom. Za vanjsku petlju, poslužite se razredom [`model_selection.KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) koji zna kako raditi preklope iz danih mu podataka. Proučite kako se mora definirati rječnik vrijednosti hiperparametara (treba se držati posebnog načina imenovanja varijabli) na http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py.\n",
    "\n",
    "Funkcija vraća listu generalizacijskih pogrešaka kroz preklope vanjske petlje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "\n",
    "def nested_kfold_cv(clf, param_grid, X, y, k1=10, k2=3):\n",
    "    outter_folds = KFold(n_splits=k1, shuffle=True)\n",
    "    inner_folds = KFold(n_splits=k2, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=inner_folds)\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    nested_score = cross_val_score(grid_search, X, y, cv=outter_folds)\n",
    "    print grid_search.best_score_\n",
    "    print grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Zašto nam treba još jedna razina k-struke provjere?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "Dodatno, vrijedi znati kako iskoristiti `GridSearchCV` u slučaju da moramo raditi i pretprocesiranje podataka. Stoga se i upoznajte s razredom [`pipeline.Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html), koji omogućava jednostavno stvaranje cjevovoda modela (bilo za pretprocesiranje ili za klasifikaciju/regresiju/itd.) koji se kasnije može koristiti kao bilo koji drugi model (jedan objekt s `fit` i `predict` funkcijama).\n",
    "\n",
    "Pripremite cjevovod koji se sastoji od [standardnog skaliranja](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) i SVM-a s RBF-jezgrom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='rbf')),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "\n",
    "Naučite vaš cjevovod na `glass` skupu podataka koristeći k-struku ugniježđenu unakrsnu provjeru (korištenjem Vaše funkcije s pretpostavljenim vrijednostima za `k1` i `k2`). Trebate isprobati hiperparametre $C\\in\\{2^{-3},2^{-4},\\dots,2^{3}\\}$ i $\\gamma\\in\\{2^{-3},2^{-4},\\dots,2^{3}\\}$. Ispišite srednju vrijednost generalizacijske pogreške."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.700934579439\n",
      "{'svm__max_iter': -1, 'svm__coef0': 0.0, 'svm': SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.125, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'svm__random_state': None, 'scaler__copy': True, 'scaler': StandardScaler(copy=True, with_mean=True, with_std=True), 'svm__probability': False, 'svm__degree': 3, 'scaler__with_std': True, 'svm__shrinking': True, 'scaler__with_mean': True, 'svm__verbose': False, 'svm__C': 2, 'steps': [('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.125, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))], 'svm__gamma': 0.125, 'svm__class_weight': None, 'svm__tol': 0.001, 'svm__decision_function_shape': None, 'svm__kernel': 'rbf', 'svm__cache_size': 200}\n"
     ]
    }
   ],
   "source": [
    "model = pipeline\n",
    "param_grid = {\n",
    "    'svm__C': [2**i for i in range(-3, 3)],\n",
    "    'svm__gamma': [2**i for i in range(-3, 3)]\n",
    "}\n",
    "\n",
    "nested_kfold_cv(model, param_grid, glass_X, glass_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Statističko testiranje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenarij koji nas najviše zanima jest usporedba dvaju klasifikatora, odnosno, je li jedan od njih zaista bolji od drugog. Jedini način kako to možemo zaista potvrditi jest statističkom testom, u našem slučaju **uparenim t-testom**. Njime ćemo se baviti u ovom zadatku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "\n",
    "U ovom zadatku bavit ćemo se testiranjem je li razlika u perfomansama dva klasifikatora statistički značajna. Nad našim skupom podataka proveli smo unakrsnu provjeru s $N \\in \\{5, 10, 50\\}$ preklopa. Kao rezultat dobili smo tri skupa rezultata (po jedan za svaku vrijednost $N$) u kojima imamo uparene perfomanse za oba klasifikatora kroz preklope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "C1_scores_5folds = np.random.normal(78, 4, 5)\n",
    "C2_scores_5folds = np.random.normal(81, 2, 5)\n",
    "\n",
    "C1_scores_10folds = np.random.normal(78, 4, 10)\n",
    "C2_scores_10folds = np.random.normal(81, 2, 10)\n",
    "\n",
    "C1_scores_50folds = np.random.normal(78, 4, 50)\n",
    "C2_scores_50folds = np.random.normal(81, 2, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "Iskoristite ugrađenu funkciju [`scipy.stats.ttest_rel`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_rel.html) za provedbu uparenog t-testa nad podatcima s $N=10$ preklopa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "\n",
    "Zatim sami implementirajte funkciju `paired_t_test` koja provodi upareni t-test. Funkcija prima dvije liste vrijednosti, a  vraća dvije vrijednosti: iznos t-statistike i p-vrijednost. Za računanje p-vrijednosti uzmite u obzir da t-statistika ima studentovu razdiobu s $N-1$ stupnjeva slobode. Kao što znate, p-vrijednost jest zapravo $P(x < -t) + P(x > t)$, gdje $t$ označava apsolutni iznos t-statistike. Do ovih vjerojatnosti možete doći preko funkcija `scipy.stats.t.cdf` ili `scipy.stats.t.sf` iz paketa [`scipy.stats.t`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.t.html). Usporedite vlastitu implementaciju s onom ugrađenom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paired_t_test(data1, data2):\n",
    "    # Vaš kôd ovdje...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koju hipotezu $H_0$ i alternativnu hipotezu $H_1$ testiramo ovim testom? <br>\n",
    "**Q:** Ako odaberemo razinu značajnosti $\\alpha = 0.05$, hoćemo li odbaciti hipotezu $H_0$? <br>\n",
    "**Q:** Koja pretpostavka na vjerojatnosnu razdiobu primjera je napravljena u gornjem testu? Je li ona opravdana?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) \n",
    "\n",
    "Ponovite prethodni zadatak na skupovima podataka s 5 i 50 foldova. Razmotrite kako broj preklopa (primjera u našem uzorku) utječe na rezultat testiranja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e)\n",
    "\n",
    "Završno, naučite model logističke regresije (bez preslikavanja značajki u višu dimenziju) sa standardnim skaliranjem na način jednak onom u zadatku 1c. Isprobajte razine regularizacije $C\\in\\{2^{-3},2^{-4},\\dots,2^{3}\\}$. Nakon toga imat ćete po 10 točnosti za svaki od preklopa za svaki od dva modela (LR i SVM). Provedite upareni t-test i kažite razlikuju li se performanse ova dva modela s razinom značajnosti $\\alpha = 0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koji je model u konačnici bolji i je li ta prednost značajna uz $\\alpha = 0.05$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Algoritam k-srednjih vrijednosti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "Za početak, implementirajte algoritam k-srednjih vrijednosti nadopunjući donji predložak razreda ``DIYKMeans``. Konstruktor razreda prima početne centroide grupa (``init_centroids``), broj grupa $K$ (``num_clusters``) i maksimalan broj iteracija algoritma (``max_iter``). Nadalje, nadopunite funkciju ``fit(X)`` koja provodi učenje grupiranja iz danih podataka ``X``, te funkciju ``predict(X)`` koja predviđa grupu danih podataka ``X``. Algoritam se provodi dok se ne dosegne ``max_iter`` iteracija ili dok razlika između $J$ dviju iteracija ne padne ispod `tol`. Pripremite skup podataka po volji i ručno provedite algoritam te usporedite izlaze Vaše implementacije modela (završni centroidi, predikcije, itd.).\n",
    "\n",
    "**NB**: Pripazite na tip podataka ulaznih primjera. Ako su ulazni podaci vektori cijelih brojeva, računanje njihove srednje vrijednosti može *opet* rezultirati cjelobrojnim srednjim vrijednostima. Tip podataka možete eksplicitno definirati pri stvaranju numPy-polja, o čemu možete pročitati [ovdje](https://docs.scipy.org/doc/numpy/user/basics.types.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "class DIYKMeans(object):\n",
    "    \n",
    "    def __init__(self, init_centroids, num_clusters=3, max_iter=300, tol=0.001):\n",
    "        \n",
    "        if init_centroids is None or init_centroids.shape[0] != num_clusters:\n",
    "            raise Exception(\"Exactly `num_clusters` of initial centroids must be provided.\")\n",
    "        \n",
    "        self.num_clusters = num_clusters\n",
    "        self.centroids = deepcopy(init_centroids)\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "        \n",
    "    def fit(self, X):\n",
    "        \n",
    "        # Vaš kôd ovdje...\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        # Vaš kôd ovdje...\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kao što možete pretpostaviti, najveći problem ovog algoritma je to što unaprijed zahtjeva broj grupa u koje će grupirati podatke. Ta informacija nam često nije dostupna (kao što nam nisu dostupne ni oznake primjera) te je stoga potrebno nekako izabrati najbolju vrijednost hiperparametra $K$. Jedan od naivnijih pristupa jest **metoda lakta/koljena** (engl. *elbow method*) koja se temelji na tome da se izabere ona vrijednost hiperparametra $K$ za koju se dogodi nagla promjena kriterijske funkcije algoritma k-srednjih vrijednosti $J$. Iz laičke perspektive, uzima se onaj $K$ za koji se na krivulji od $J$ s obzirom na $K$ pojavi \"lakat\". \n",
    "\n",
    "Sada ćemo se, kao i inače, prebaciti na ugrađenu implementaciju algoritma k-srednjih vrijednosti, dostupnoj u [`cluster.KMeans`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). Iskoristite skup podataka `Xp` dan niže. Isprobajte vrijednosti hiperparametra $K$ iz $[0,1,\\ldots,15]$. Ne trebate dirati nikakve hiperparametre modela osim $K$. Iscrtajte krivulju od $J$ u ovisnosti o broju grupa $K$.\n",
    "\n",
    "**NB**: Kriterijska funkcija algoritma k-srednjih vrijednosti još se i naziva **inercijom** (engl. *inertia*). Za naučeni model, vrijednost kriterijske funkcije $J$ dostupna je kroz razredni atribut `inertia_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "Xp, yp = make_blobs(n_samples=300, n_features=2, centers=[[0, 0], [1.0, 1.0], [0, 2]], \n",
    "                    cluster_std=[0.45, 0.3, 0.45], random_state=96)\n",
    "plt.scatter(Xp[:,0], Xp[:,1], c=yp, cmap=plt.get_cmap(\"cool\"), s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Vaš kôd ovdje...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koju biste vrijednost hiperparametra $K$ izabrali na temelju ovog grafa? Zašto? <br>\n",
    "**Q:** Je li ova metoda robusna? <br>\n",
    "**Q:** Znate li još koji način kako izabrati vrijednost hiperparametra $K$? <br>\n",
    "**Q:** Možemo li izabrati onaj $K$ koji minimizira pogrešku $J$? Objasnite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "\n",
    "Kako evaluirati točnost modela grupiranja ako imamo stvarne oznake svih primjera (a u našem slučaju imamo, jer smo mi ti koji smo generirali podatke)? Često korištena mjera jest **Randov indeks** koji je zapravo pandan točnosti u zadatcima klasifikacije. Implementirajte funkciju `rand_index_score(y_gold, y_predict)` koja ga računa. Funkcija prima dva argumenta: listu stvarnih grupa kojima primjeri pripadaju (`y_gold`) i listu predviđenih grupa (`y_predict`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rand_index_score(y_gold, y_predict):\n",
    "    \n",
    "    # Vaš kôd ovdje...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zatim evaluirajte gornji model (onaj s najboljim $K$) na podatcima `Xp` (efektivno skup za učenje) koristeći Randov indeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako biste svojim riječima opisali što mjeri Randov indeks? <br>\n",
    "**Q:** Koji su glavni problemi ove metrike?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pretpostavke algoritma k-srednjih vrijednosti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovom i sljedećim podzadatcima fokusirat ćemo se na temeljne pretpostavke algoritma k-srednjih vrijednosti te što se događa ako te pretpostavke nisu zadovoljene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "\n",
    "Prvo, krenite od podataka `X1`, koji su generirani korištenjem funkcije [`datasets.make_blobs`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html), koja stvara grupe podataka pomoću izotropskih Gaussovih distribucija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X1, y1 = make_blobs(n_samples=1000, n_features=2, centers=[[0, 0], [1.3, 1.3]], cluster_std=[0.15, 0.5], random_state=96)\n",
    "plt.scatter(X1[:,0], X1[:,1], c=y1, cmap=plt.get_cmap(\"cool\"), s=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naučite model k-srednjih vrijednosti (idealno pretpostavljajući $K=2$) na gornjim podatcima i prikažite dobiveno grupiranje (proučite funkciju [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter), posebice argument `c`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Što se dogodilo? Koja je pretpostavka algoritma k-srednjih vrijednosti ovdje narušena? <br>\n",
    "**Q:** Što biste morali osigurati kako bi algoritam pronašao ispravne grupe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "Isprobajte algoritam k-srednjih vrijednosti na podatcima generiranim korištenjem funkcije [`datasets.make_circles`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html), koja stvara dvije grupe podataka tako da je jedna unutar druge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X2, y2 = make_circles(n_samples=1000, noise=0.15, factor=0.05, random_state=96)\n",
    "plt.scatter(X2[:,0], X2[:,1], c=y2, cmap=plt.get_cmap(\"cool\"), s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovno, naučite model k-srednjih vrijednosti (idealno pretpostavljajući $K=2$) na gornjim podatcima i prikažite dobiveno grupiranje (proučite funkciju [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter), posebice argument `c`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Što se dogodilo? Koja je pretpostavka algoritma k-srednjih vrijednosti ovdje narušena? <br>\n",
    "**Q:** Što biste morali osigurati kako bi algoritam pronašao ispravne grupe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Završno, isprobat ćemo algoritam na sljedećem umjetno stvorenom skupu podataka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X31, y31 = make_blobs(n_samples=1000, n_features=2, centers=[[0, 0]], cluster_std=[0.2], random_state=69)\n",
    "X32, y32 = make_blobs(n_samples=50, n_features=2, centers=[[0.7, 0.5]], cluster_std=[0.15], random_state=69)\n",
    "X33, y33 = make_blobs(n_samples=600, n_features=2, centers=[[0.8, -0.4]], cluster_std=[0.2], random_state=69)\n",
    "plt.scatter(X31[:,0], X31[:,1], c=\"#00FFFF\", s=20)\n",
    "plt.scatter(X32[:,0], X32[:,1], c=\"#F400F4\", s=20)\n",
    "plt.scatter(X33[:,0], X33[:,1], c=\"#8975FF\", s=20)\n",
    "\n",
    "# Just join all the groups in a single X.\n",
    "X3 = np.vstack([X31, X32, X33])\n",
    "y3 = np.hstack([y31, y32, y33])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovno, naučite model k-srednjih vrijednosti (ovaj put idealno pretpostavljajući $K=3$) na gornjim podatcima i prikažite dobiveno grupiranje (proučite funkciju [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter), posebice argument `c`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Što se dogodilo? Koja je pretpostavka algoritma k-srednjih vrijednosti ovdje narušena? <br>\n",
    "**Q:** Što biste morali osigurati kako bi algoritam pronašao ispravne grupe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)\n",
    "\n",
    "Sada kada ste se upoznali s ograničenjima algoritma k-srednjih vrijednosti, isprobat ćete grupiranje modelom mješavine Gaussa (*Gaussian Mixture Models; GMM*), koji je generalizacija algoritma k-srednjih vrijednosti (odnosno, algoritam k-srednjih vrijednosti specijalizacija je GMM-a). Implementacija ovog modela dostupna je u [`mixture.GaussianMixture`](http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture). Isprobajte ovaj model (s istim pretpostavkama o broju grupa) na podacima iz podzadataka (a)-(c). Ne morate mijenjati nikakve hiperparametre ni postavke osim broja komponenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Vaš kôd ovdje..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Uspjeva li GMM riješiti \"probleme\" koje ima algoritam k-srednjih vrijednosti? Zašto?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
